{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classifier\n",
    "\n",
    "In this notebook you will create both, an mnist tabular dataset and a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- import the Operating System (os) module in python and any other library you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- As you can see each class has its own folder (Do it only for train). \n",
    "\n",
    "    - Iterate folder by folder ( os.listdir() )\n",
    "    - Inside each folder: \n",
    "        1.- Read the image\n",
    "        2.- Reshape it into a flat array (784,)\n",
    "        3.- Save the data into a pandas dataframe apending the column name as the class\n",
    "    - Save the data into a CSV\n",
    "\n",
    "    Note: if it takes to long try doing only 100 images per folder for the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shuvomamun'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory path\n",
    "path = 'dataset/trainingSet'\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "# Creating empty dataframe\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "# Creating for loop to extract all images from each folder\n",
    "for file in dir_list:\n",
    "    \n",
    "    #Iterate folder by folder\n",
    "    imgs = os.listdir(path+'/'+file)\n",
    "    \n",
    "    # Creating an array with all zeros\n",
    "    arr = np.zeros((len(imgs),785))\n",
    "    for i,img in enumerate(imgs):\n",
    "        \n",
    "        #Opening the images\n",
    "        imag = Image.open(path+'/'+file+'/'+img)\n",
    "        \n",
    "        #Converting images into array\n",
    "        arry = np.array(imag,dtype=float)\n",
    "        \n",
    "        # Reshaping image to 1D\n",
    "        arry = arry.flatten()\n",
    "        \n",
    "        #Adding features\n",
    "        arr[i,:784]=arry\n",
    "        \n",
    "        #Adding target labels\n",
    "        arr[i,784]=int(file)\n",
    "    # Converting array into dataframe\n",
    "    df2 = pd.DataFrame(arr)\n",
    "    #\n",
    "    df = pd.concat([df1,df2])\n",
    "    df1 = df\n",
    "    print(df.shape)\n",
    "df.to_csv('numerical1.csv', index=False, header=False)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/trainingSample'\n",
    "\n",
    "img = Image.open('dataset/trainingSample/0/img_1.jpg')\n",
    "arry = np.array(img, dtype=float)\n",
    "arry = arry.flatten()\n",
    "#df = pd.DataFrame(arry)\n",
    "#df\n",
    "#dir_list = os.listdir(path)\n",
    "# df = pd.DataFrame()\n",
    "# for file in dir_list:\n",
    "#     imgs = os.listdir(path+'/'+file)\n",
    "#     for img in imgs:\n",
    "#         imag = Image.open(path+'/'+file+'/'+img)\n",
    "#         arry = np.array(imag, dtype=float)\n",
    "#         #print(arry.shape)\n",
    "#         arry = arry.reshape(784,)\n",
    "#         #print(arry)\n",
    "#     df1 = pd.DataFrame({'Image': arry}).T\n",
    "#     df1['class'] = file\n",
    "#     df = df.append(df1)\n",
    "#     print(df.shape)\n",
    "#df.to_csv('numerical.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Load the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('numerical1.csv')\n",
    "print(data.head())\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Create a dictionary of models (No preprocessing needed, it has already been done).\n",
    "    \n",
    "    Include both, tree models and mult models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "classifiers = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(n_estimators=100),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"Gradientboosting\": GradientBoostingClassifier(n_estimators=100),\n",
    "    \"XGB\": XGBClassifier(n_estimators=100),\n",
    "    \"LGB\" : LGBMClassifier(n_estimators=100),\n",
    "    \"Catboost\": CatBoostClassifier(n_estimators=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Using either cross validation or stratification find out which is the best model\n",
    "    - Base your code on the previous two days examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "import time\n",
    "\n",
    "skf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "results =  []\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "    print(\"Training\" + name + \"Model\")\n",
    "    start_time = time.time()\n",
    "    prediction = model_selection.cross_val_predict(model, X, y, cv=skf)\n",
    "    total_time = time.time() - start_time\n",
    "    print(\"Done\" + name + \"Model\")\n",
    "\n",
    "    results.append({\n",
    "        \"Model Name\": name,\n",
    "        \"Accuracy\": metrics.accuracy_score(y, prediction)*100,\n",
    "        \"Bal Acc\": metrics.balanced_accuracy_score(y, prediction),\n",
    "        \"Time\": total_time\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Can you rotate an image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50a93f2fecfd00da27f8930a2c1c74e92db967b2162384b3e8848f4306dc0d4b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
